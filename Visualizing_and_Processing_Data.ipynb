{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this Notebook is to use the results of the [Stack Overflow 2022 Developer Survey](https://insights.stackoverflow.com/survey) to train a regression neural network for predicting total compensation among programmers. This notebook can be thought of being divided into three different sections: data exploration and visualization, data preprocessing, and the implementation of the neural net. "
      ],
      "metadata": {
        "id": "1duyBbL90E3D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_tROspedhx5h"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import itertools\n",
        "import math\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "try:\n",
        "  from category_encoders import *\n",
        "except ModuleNotFoundError:\n",
        "  ! pip install category_encoders\n",
        "  from category_encoders import *\n",
        "import torch\n",
        "from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from https://insights.stackoverflow.com/survey year is 2022\n",
        "\n",
        "try:\n",
        "  survey = pd.read_csv(\"survey_results_public.csv\")\n",
        "except FileNotFoundError:\n",
        "  ! gdown 1T1WH1mZh9xg4b7dmt3mk2mZrvXgzocvS # survey_results_public.csv\n",
        "  survey = pd.read_csv(\"survey_results_public.csv\")"
      ],
      "metadata": {
        "id": "oCNE6Ag5ly6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "survey = pd.read_csv(\"survey_results_public.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "7R6iT1wOvtMy",
        "outputId": "7f3307ee-92da-4472-d96b-65e715b4b7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d0d44657-1770-4ffc-8238-621aed05e1ee\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d0d44657-1770-4ffc-8238-621aed05e1ee\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_percent_this_value(data, feature, value):\n",
        "  number = data[data[feature] == value].shape[0]\n",
        "  ratio = 100 * number / data[feature].size\n",
        "  print(f\"{number} records, or {ratio}%, have value {value} for feature {feature}\")"
      ],
      "metadata": {
        "id": "mkPOSQJEePlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_percent_not_nan(data, feature):\n",
        "  number = data[feature].notna().sum()\n",
        "  ratio = round(100 * number / data[feature].size, 2)\n",
        "  print(f\"{number} records, or {ratio}%, have a non-NaN value for feature {feature}\")"
      ],
      "metadata": {
        "id": "DLQVe4a5eP4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unique_values_including (dataframe, feature, string):\n",
        "  uniques = dataframe[feature].unique()\n",
        "  result = ()\n",
        "  for response in uniques:\n",
        "    if string in str(response):\n",
        "      result.append(response)\n",
        "  return result"
      ],
      "metadata": {
        "id": "oVziQh9MZfDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For columns that include a mix of checkboxes, this will return the individual checkboxes, as opposed to each unique combination of them\n",
        "def get_atoms(dataset, field):\n",
        "  uniques = dataset[field].unique()\n",
        "  atoms = []\n",
        "  for unique in uniques:\n",
        "    if unique is np.NaN:\n",
        "      continue\n",
        "    asList = unique.split(';')\n",
        "    for token in asList:\n",
        "      toAdd = token.strip()\n",
        "      if toAdd not in atoms:\n",
        "        atoms.append(toAdd)\n",
        "  return atoms"
      ],
      "metadata": {
        "id": "i0VzRcdVWBCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Deprecated\n",
        "def make_piechart(dataset, feature, dicttext):\n",
        "  copy = dataset.dropna(subset = [feature], inplace = False)\n",
        "  explode_size = 0.05\n",
        "  counts = []\n",
        "  atoms = get_atoms(copy, feature)\n",
        "  for atom in atoms:\n",
        "    counts.append(copy[copy[feature].str.contains(atom)].shape[0])\n",
        "  agedict = dict(zip(atoms, counts))\n",
        "  explode = [explode_size for index in range(len(counts))]\n",
        "  fig, ax = plt.subplots(figsize = (30, 8))\n",
        "  ax.pie(counts, labels=atoms, autopct = '%1.1f%%', explode = explode, shadow = True)\n",
        "  print(dicttext)\n",
        "  print(agedict)"
      ],
      "metadata": {
        "id": "2jSIPZ8suCY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Makes a bar graph of a categorical feature\n",
        "def make_bar_graph(dataset, feature, title, xlabel, ylabel, log = False):\n",
        "  atoms = get_atoms(dataset, feature)\n",
        "  copy = dataset.dropna(subset = [feature], inplace = False)\n",
        "  counts = []\n",
        "  if np.NaN in atoms:\n",
        "    atoms.remove(np.NaN)\n",
        "  for atom in atoms:\n",
        "    if 'Other' in atom:\n",
        "      counts.append(copy[copy[feature].str.contains('Other')].shape[0])\n",
        "    else:\n",
        "      counts.append(copy[copy[feature].str.contains(atom)].shape[0])\n",
        "  fig, ax = plt.subplots(figsize = (30, 8))\n",
        "  ourdict = dict(zip(counts, atoms))\n",
        "  sorted_keys = sorted(ourdict.keys(), reverse = True)\n",
        "  labels = []\n",
        "  for key in sorted_keys:\n",
        "    labels.append(ourdict.get(key))\n",
        "  pps = ax.bar(x = labels, height = sorted_keys, log = log, align = 'center')\n",
        "  ax.set_xlabel(xlabel)\n",
        "  ax.set_xticklabels(labels, rotation=90)\n",
        "  ax.set_title(title)\n",
        "  ax.set_ylabel(ylabel)\n",
        "  # Thanks to https://www.tutorialspoint.com/adding-value-labels-on-a-matplotlib-bar-chart\n",
        "  for p in pps:\n",
        "   height = p.get_height()\n",
        "   ax.annotate('{}%'.format(round(100.0 * height / copy.shape[0], 1)),\n",
        "      xy=(p.get_x() + p.get_width() / 2, height),\n",
        "      xytext=(0, 3), # 3 points vertical offset\n",
        "      textcoords=\"offset points\",\n",
        "      ha='center', va='bottom')"
      ],
      "metadata": {
        "id": "9XYYMPWZFqwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Deprecated and kept in the case it's needed later\n",
        "def gender_piechart(bracket):\n",
        "  large_explode = 0.2\n",
        "  small_explode = 0.5\n",
        "  counts = (bracket[0].shape[0], bracket[1].shape[0], bracket[2].shape[0], bracket[3].shape[0])\n",
        "  labels = ('Male', 'Female', 'Nonbinary, Genderqueer, or Gender-Nonconforming', 'Prefer not to Say')\n",
        "  explode = (large_explode, small_explode, small_explode, small_explode)\n",
        "  fig, ax = plt.subplots(figsize = (30, 8))\n",
        "  ax.pie(counts, labels=labels, autopct = '%1.1f%%', shadow = True, explode=explode)"
      ],
      "metadata": {
        "id": "zMA5zhqmuKcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Deprecated and kept in the case it's needed later\n",
        "def age_piechart(dataset):\n",
        "  explode_size = 0.05\n",
        "  agecounts = []\n",
        "  for unique in dataset['Age'].unique():\n",
        "    agecounts.append(dataset[dataset['Age'] == unique].shape[0])\n",
        "  agecounts[-1] = dataset['Age'].isna().sum() #Doesn't pick up NaN values, doing these manually\n",
        "  labels = ('25-34', '35-44', '18-24', '45-54', '55-65', '65+', 'Didn\\'t say', '<18', 'No Response')\n",
        "  agedict = dict(zip(labels, agecounts))\n",
        "  explode = [explode_size for index in range(len(agecounts) - 4)]\n",
        "  fig, ax = plt.subplots(figsize = (30, 8))\n",
        "  ax.pie(agecounts[:-4], labels=labels[:-4], autopct = '%1.1f%%', explode = explode, shadow = True)\n",
        "  print('The dictionary of each age group and the number of respondents is as follows:\\n', agedict)"
      ],
      "metadata": {
        "id": "K8NNdOu0EVf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shows how many years of experience the  respondents tend to have\n",
        "# Has to be separate from generic bar graph function since the data is quantitative\n",
        "def workexp_bar_graph(dataframe, title):\n",
        "  feature = 'YearsCodePro'\n",
        "  copy = dataframe.dropna(subset = [feature], inplace = False)\n",
        "  uniques = copy[feature].unique()\n",
        "  counts = []\n",
        "  for atom in uniques:\n",
        "      counts.append(copy[copy[feature] == atom].shape[0])\n",
        "  fig, ax = plt.subplots(figsize = (30, 8))\n",
        "  ourdict = dict(zip(counts, uniques))\n",
        "  sorted_keys = sorted(ourdict.keys(), reverse = True)\n",
        "  labels = []\n",
        "  for key in sorted_keys:\n",
        "    labels.append(ourdict.get(key))\n",
        "  pps = ax.bar(x = labels, height = sorted_keys, align = 'center')\n",
        "  ax.set_xlabel('Work Experience in Years')\n",
        "  ax.set_xticklabels(labels, rotation=90)\n",
        "  ax.set_title(title)\n",
        "  ax.set_ylabel('Number of Respondents')\n",
        "  # Many thanks to https://www.tutorialspoint.com/adding-value-labels-on-a-matplotlib-bar-chart\n",
        "  for p in pps:\n",
        "   height = p.get_height()\n",
        "   ax.annotate('{}%'.format(round(100.0 * height / copy.shape[0], 1)),\n",
        "      xy=(p.get_x() + p.get_width() / 2, height),\n",
        "      xytext=(0, 3), # 3 points vertical offset\n",
        "      textcoords=\"offset points\",\n",
        "      ha='center', va='bottom')"
      ],
      "metadata": {
        "id": "zIv4objFMjC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option(\"max_columns\", None)\n",
        "target = 'ConvertedCompYearly'\n",
        "survey.sample(3)"
      ],
      "metadata": {
        "id": "4u-KOh0ViKfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Exploration"
      ],
      "metadata": {
        "id": "xpE6er4W0-6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The survey features people paid at different intervals and in different currencies. What a nightmare to process! Thankfully, we're given a feature known as ConvertedCompYearly. As it says on the website: \n",
        "\n",
        "`We converted salaries from user currencies to USD using the exchange rate on May 24, 2022 and also converted to annual salaries assuming 12 working months and 50 working weeks. `\n",
        "\n",
        "This is perfect for us! But how many records actually have data for this feature?"
      ],
      "metadata": {
        "id": "CpgZ2WR1Hrip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def valid_targets(dataframe):\n",
        "  print_percent_not_nan(dataframe, \"ConvertedCompYearly\")\n",
        "  median = dataframe[\"ConvertedCompYearly\"].median()\n",
        "  mean = round(dataframe[\"ConvertedCompYearly\"].mean(), 2)\n",
        "  print(f\"the median total compensation is ${round(median / 1000, 2)}k, the average total compensation is ${round(mean / 1000, 2)}k\")"
      ],
      "metadata": {
        "id": "evt-IpDfidZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm = survey.dropna(subset = [target]).copy()\n",
        "valid_targets(survey)\n",
        "norm.isna().sum() / (0.01 * norm.shape[0])"
      ],
      "metadata": {
        "id": "NP5gH5vhcew_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Delete Irrelevant Features"
      ],
      "metadata": {
        "id": "RBsjP8AK7qfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it comes to feature selection, this model will be pruning down as many features as possible to keep the neural net lean. Someof the names don't describe what the feature describes very well, but there's luckily a copy of the survey provided with the data. The following are some features that can confidently be removed: \n",
        "\n",
        "*   ResponseId is an ID number\n",
        "*   SurveyEase and SurveyLength are about how the person felt about the survey itself\n",
        "*   CompFreq, CompTotal, and Currency are all rolled into the target variable\n",
        "*   Blockchain opinions, thoughts on certain technologies, Stack Overflow use, and personal OS are unlikely to matter\n",
        "*   'Knowledge' refers to encountering knowledge silos and likely doesn't matter\n",
        "*   Frequency, TimeSearch, and TimeAnswering are also related to SO itself\n",
        "*   TrueFalse features are extremely unclear as to what it is even with a copy of the survey\n",
        "*   BuyNewTool refers to how they would decide on buying a new tool\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vmOdVY7Qk2Qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Warning, in-place!\n",
        "def delete_irrelevant_columns(dataframe):\n",
        "  oldSize = dataframe.shape[1]\n",
        "  del dataframe[\"ResponseId\"] \n",
        "  del dataframe['SurveyEase'] \n",
        "  del dataframe['SurveyLength']\n",
        "  del dataframe['CompFreq'] \n",
        "  del dataframe['CompTotal']\n",
        "  del dataframe['Currency']\n",
        "  del dataframe['Blockchain']\n",
        "  del dataframe['BuyNewTool']\n",
        "  del dataframe['TBranch']\n",
        "  for col in dataframe:\n",
        "    if 'WantToWorkWith' in col or 'Personal' in col or 'SO' in col or 'Frequency' in col or 'Knowledge' in col or 'Time' in col or 'TrueFalse' in col: \n",
        "      del dataframe[col]\n",
        "  newSize = dataframe.shape[1]\n",
        "  print(f\"went from {oldSize} to {newSize} features\")\n",
        "  print(f\"size of the Dataframe is now {dataframe.shape}\")"
      ],
      "metadata": {
        "id": "49vCwx5qhJM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Delete Highly-Null Features"
      ],
      "metadata": {
        "id": "8WE863xK7uwA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many of the features are null? `VCHostingProfessional use` is literally entirely null. `LearnCodeCoursesCert` is over halfway null, while `LearnCodeOnline`, `MiscTechHaveWorkedWith`, `ProfessionalTech`, and  `Onboarding` are all over 30% null and `PlatformHaveWorkedWith`, `WebframeHaveWorkedWith`, `OfficeStackAsyncHaveWorkedWith`, `ICorPM`, and `WorkExp` are all over 20% null."
      ],
      "metadata": {
        "id": "buVqHCs68-Ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete_irrelevant_columns(norm)\n",
        "norm.isna().sum() / (0.01 * norm.shape[0])"
      ],
      "metadata": {
        "id": "j-Bkrf_T9A_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Warning! In place!\n",
        "def delete_high_nulls(dataframe):\n",
        "  oldSize = dataframe.shape[1]\n",
        "  del dataframe['VCHostingProfessional use']\n",
        "  del dataframe['LearnCodeCoursesCert']\n",
        "  del dataframe['LearnCodeOnline']\n",
        "  del dataframe['PlatformHaveWorkedWith']\n",
        "  del dataframe['WebframeHaveWorkedWith']\n",
        "  del dataframe['MiscTechHaveWorkedWith']\n",
        "  del dataframe['ToolsTechHaveWorkedWith']\n",
        "  del dataframe['OfficeStackAsyncHaveWorkedWith']\n",
        "  del dataframe['ICorPM']\n",
        "  del dataframe['Onboarding']\n",
        "  del dataframe['ProfessionalTech']\n",
        "  newSize = dataframe.shape[1]\n",
        "  print(f\"went from {oldSize} to {newSize} features\")\n",
        "  print(f\"size of the Dataframe is now {dataframe.shape}\")"
      ],
      "metadata": {
        "id": "hmwq6h7W3OY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_high_nulls(norm)\n",
        "norm.isna().sum() / (0.01 * norm.shape[0])"
      ],
      "metadata": {
        "id": "n7mS2w9g-0MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Delete Redundant Work Experience Features"
      ],
      "metadata": {
        "id": "e6nt0CW376vq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`WorkExp` and `YearsCodePro` are over 90% correlated, while `YearsCode` and `YearsCodePro` are also 90% correlated. Of these, `WorkExp` correlates more closely to the target variable of these features, but is also highly null at 28%. Thus, we will be using `YearsCodePro` among these instead, since it has better correlation to the target variable than `YearsCode` and is less than 1% null."
      ],
      "metadata": {
        "id": "FEY5KuHnJBCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def experience_correlations(dataframe):\n",
        "  compcopy = dataframe.copy()\n",
        "  compcopy.dropna(subset = ['WorkExp', 'YearsCodePro', 'YearsCode'], inplace = True)\n",
        "  compcopy['YearsCodePro'].replace({'Less than 1 year':0, 'More than 50 years':51 }, inplace = True)\n",
        "  compcopy['YearsCode'].replace({'Less than 1 year':0, 'More than 50 years':51 }, inplace = True)\n",
        "  compcopy = compcopy.astype({'YearsCodePro':int, 'YearsCode':int})\n",
        "  print(compcopy.corr())"
      ],
      "metadata": {
        "id": "b5L9sdhDJBd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experience_correlations(norm)"
      ],
      "metadata": {
        "id": "FseltQlLjE1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interestingly enough, if we're to only consider those who make a very large amount of money, these features all have a weak *negative* correlation to the target variable."
      ],
      "metadata": {
        "id": "ycNE5buWl7Ht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upper_exp_corrs(dataframe):\n",
        "  high_target = 550_000\n",
        "  experience_correlations(dataframe[dataframe[target] > high_target])\n",
        "\n",
        "upper_exp_corrs(norm)"
      ],
      "metadata": {
        "id": "mclCu3dil6eA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_years_cols(dataframe):\n",
        "  oldSize = dataframe.shape[1]\n",
        "  del dataframe['YearsCode']\n",
        "  del dataframe['WorkExp']\n",
        "  newSize = dataframe.shape[1]\n",
        "  print(f\"went from {oldSize} to {newSize} features\")\n",
        "  print(f\"size of the Dataframe is now {dataframe.shape}\")"
      ],
      "metadata": {
        "id": "PyFoVKhhjrC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_years_cols(norm)\n",
        "norm.isna().sum() / (0.01 * norm.shape[0])"
      ],
      "metadata": {
        "id": "olrv2t_-jsFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Discretionarily Deleted Features"
      ],
      "metadata": {
        "id": "OpgkJZ688C87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, to help keep the features as lean as possible, the following features are discretionarily removed."
      ],
      "metadata": {
        "id": "l1RHZBH63X2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting some of the borderline features that might or might not help predict\n",
        "def delete_unlikely_cols(data):\n",
        "  oldSize = data.shape[1]\n",
        "  del data['RemoteWork']\n",
        "  del data['Employment']\n",
        "  del data['LearnCode']\n",
        "  del data['PurchaseInfluence']\n",
        "  del data['DatabaseHaveWorkedWith']\n",
        "  del data['NEWCollabToolsHaveWorkedWith']\n",
        "  del data['OpSysProfessional use']\n",
        "  del data['VersionControlSystem']\n",
        "  del data['VCInteraction']\n",
        "  del data['OfficeStackSyncHaveWorkedWith']\n",
        "\n",
        "  newSize = data.shape[1]\n",
        "  print(f\"went from {oldSize} to {newSize} features\")\n",
        "  print(f\"size of the Dataframe is now {data.shape}\")"
      ],
      "metadata": {
        "id": "eH0tRQvt3vIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_unlikely_cols(norm)\n",
        "norm.isna().sum() / (0.01 * norm.shape[0])"
      ],
      "metadata": {
        "id": "1VoKhVv32BIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Visualization"
      ],
      "metadata": {
        "id": "Jf-cF_yX8MGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Overall Total Compensation Visualization"
      ],
      "metadata": {
        "id": "pie_XrVf8Ugq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the target variable, the distribution is quite heavily weighted toward \\$55k or so, with an average of just over \\$170k."
      ],
      "metadata": {
        "id": "k6R9JgeZJjfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_salary (dataset, title):\n",
        "  maxSalary = 550_000\n",
        "  stepNum = 101\n",
        "  scaleFactor = 1_000\n",
        "  scaleSuffix = 'k'\n",
        "  graphBins = np.linspace(0, maxSalary/scaleFactor, stepNum)\n",
        "  fig, ax = plt.subplots(figsize=(20, 5))\n",
        "  ax.hist(dataset[target] / scaleFactor, bins = graphBins)\n",
        "  ax.set_xlabel('TC in thousands, bin size = $' + str(int(maxSalary / (stepNum - 1))))\n",
        "  ax.set_ylabel('Number of Respondents')\n",
        "  percent = 100 * dataset[dataset[target] < maxSalary].shape[0] / dataset[target].shape[0]\n",
        "  percent = round(percent, 2)\n",
        "  outsideRange = str(percent) + \"% of respondents make within $\" + str(int(maxSalary / scaleFactor)) + scaleSuffix\n",
        "  average = \"The average total compensation is $\" + str(round(dataset[target].mean() / scaleFactor, 2)) + scaleSuffix\n",
        "  median = \"The median total compensation is $\" + str(round(dataset[target].median() / scaleFactor, 2)) + scaleSuffix\n",
        "  ax.annotate(outsideRange, xy = (0,0), textcoords = 'figure fraction', xytext = (0.7, 0.7), fontsize = 'large')\n",
        "  ax.annotate(average, xy = (0,0), textcoords = 'figure fraction', xytext = (0.7, 0.6), fontsize = 'large')\n",
        "  ax.annotate(median, xy = (0,0), textcoords = 'figure fraction', xytext = (0.7, 0.5), fontsize = 'large')\n",
        "  ax.set_title(title)\n",
        "  dummy = np.NaN"
      ],
      "metadata": {
        "id": "TIxBQE_wciej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "america = (norm[norm['Country'] == 'United States of America'])\n",
        "visualize_salary(norm, 'Total Compensation Distribution for All Respondents')\n",
        "visualize_salary(america, 'Total Compensation Distribution for American Respondents')"
      ],
      "metadata": {
        "id": "dFaNWXUJbnM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From hereon out, we'll use `norm` to refer to respondants whose total compensation was less than or equal to $550,000 for the upper TC range, with `upper` exclusively holding those records above this cutoff."
      ],
      "metadata": {
        "id": "F60d-onImvAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "high_target = 550_000\n",
        "upper = norm[norm[target] > high_target].copy().sort_values(by = target)\n",
        "norm = norm[norm[target] <= high_target].copy()\n",
        "upper.sample(3)"
      ],
      "metadata": {
        "id": "PAg2Smu6nEY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Important Notice"
      ],
      "metadata": {
        "id": "r_ZIO_2YLaf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For all the following categorical variables, the respondents were able to pick multiple choices from an array of options. For exampe, this means the same respondent could identify as male and female, heterosexual and bisexual, as a front end developer and a data scientist, etc. In determing the distribution of these attributes, the figures shown are for the amount of respondents who *included* that option in their answer. Someone who identified as both male and female would show up in both the male salary graph and the female salary graph."
      ],
      "metadata": {
        "id": "8Qe09kjELcHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualization by Gender"
      ],
      "metadata": {
        "id": "hvveuamE7e6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pruning"
      ],
      "metadata": {
        "id": "uR0AO4qEEc8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the 'In your own words' option doesn't save what the respondent elaborated with for privacy reasons, we will drop this option from each respondent's selection. If this results in an empty Gender field, we'll change it to NaN."
      ],
      "metadata": {
        "id": "oWqJHKc5WsUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Warning! In-place!\n",
        "def prune_gender(dataframe):\n",
        "  print('Before pruning \\'in your own words\\' responses')\n",
        "  print(dataframe['Gender'].unique())\n",
        "  dataframe['Gender'].replace(inplace = True, regex = True, to_replace = ['Or, in your own words:;', 'Or, in your own words:'], value = '')\n",
        "  dataframe['Gender'].replace(inplace = True, to_replace = 'Man;', value = 'Man') #Special case\n",
        "  dataframe['Gender'].replace(inplace = True, to_replace = '', value = np.NaN)\n",
        "  print('\\n\\n\\nAfter pruning')\n",
        "  print(dataframe['Gender'].unique())\n",
        "  print('\\n\\n\\nDropping ' + str(dataframe['Gender'].isna().sum()) + ' null values for the Gender field out of ' + str(dataframe['Gender'].shape[0]))\n",
        "  dataframe.dropna(subset = ['Gender'], inplace = True)\n",
        "\n",
        "  men = dataframe[dataframe['Gender'].str.contains('Man')]\n",
        "  women = dataframe[dataframe['Gender'].str.contains('Woman')]\n",
        "  nb = dataframe[dataframe['Gender'].str.contains('Non-binary')]\n",
        "  undisclosed = dataframe[dataframe['Gender'].str.contains('Prefer not to say')]\n",
        "  return men, women, nb, undisclosed\n"
      ],
      "metadata": {
        "id": "JvJ-VqAxzmH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Pruning the main dataset')\n",
        "norm_men, norm_women, norm_nb, norm_und = prune_gender(norm)\n",
        "print('Pruning the upper earners')\n",
        "upper_men, upper_women, upper_nb, upper_und = prune_gender(upper)\n",
        "norms = (norm_men, norm_women, norm_nb, norm_und)\n",
        "uppers = (upper_men, upper_women, upper_nb, upper_und)"
      ],
      "metadata": {
        "id": "qcL2GlMNqPwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_by_gender(dataset, title, color, maxSalary, print_range = False, minSalary = 0, scaleSuffix = 'k', scaleFactor = 1_000):\n",
        "  stepNum = 101\n",
        "  graphBins = np.linspace(minSalary/scaleFactor, maxSalary/scaleFactor, stepNum)\n",
        "  fig, ax = plt.subplots(figsize = (20, 5))\n",
        "  ax.set_xlabel('Total Compensation in thousands, bin size = $' + str(int((maxSalary - minSalary) / (stepNum - 1))), fontsize = 'large')\n",
        "  ax.set_ylabel('Number of Respondents', fontsize = 'large')\n",
        "  ax.set_title(title, fontsize = 'large')\n",
        "  percent = 100 * dataset[dataset[target] <= maxSalary].shape[0] / dataset[target].shape[0]\n",
        "  percent = round(percent, 2)\n",
        "  outsideRange = str(percent) + \"% of this subset make within \" + str(int(maxSalary / scaleFactor)) + scaleSuffix\n",
        "  average = \"The average total compensation is $\" + str(round(dataset[target].mean() / scaleFactor, 2)) + scaleSuffix\n",
        "  median = \"The median total compensation is $\" + str(round(dataset[target].median() / scaleFactor, 2)) + scaleSuffix\n",
        "  debug = []\n",
        "  if (print_range):\n",
        "    ax.annotate(outsideRange, xy = (graphBins[0],0), textcoords = 'figure fraction', xytext = (0.725, 0.7), fontsize = 'large')\n",
        "  ax.annotate(average, xy = (graphBins[0],0), textcoords = 'figure fraction', xytext = (0.725, 0.6), fontsize = 'large')\n",
        "  ax.annotate(median, xy = (graphBins[0],0), textcoords = 'figure fraction', xytext = (0.725, 0.5), fontsize = 'large')\n",
        "  ax.hist(dataset[target] / scaleFactor, bins = graphBins, color = color)"
      ],
      "metadata": {
        "id": "ixrwuyj5zu7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Total Compensation by Gender"
      ],
      "metadata": {
        "id": "-FYsyGAC-sta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When considering those who make less than \\$550k, the TC distribution follows a similar shape amongst the genders, but the average TC of the male group was 6.4% higher than the average TC for the female group. When looking at those making above $550k, the tables turn; women make 13.2% more than the men within this earnings bracket. Based on these figures, high-earning women are out-earning their male peers.\n",
        "\n",
        "Concerning the sample size, it should be said that there were only 56 women who reported making above \\$550k in the survey, while there were 1391 such men. And while this sample size is low, the proportion of women to men among this earnings cohort is only one percent point lower than among the under $550k cohort (more on this next).\n",
        "\n",
        "Lastly, these figures are only applicable when dividing solely by gender. There was no further dilineation among country, years of professional experience, age, ethnicity, etc."
      ],
      "metadata": {
        "id": "B-Ml3I1sdyRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Norm Dataset"
      ],
      "metadata": {
        "id": "5YXOr7-QFBH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_by_gender(norm_men, 'Total Compensation for Men (<=$' + str(int(high_target / 1000)) + 'k )', 'royalblue', high_target)"
      ],
      "metadata": {
        "id": "93ANFuAHVxbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_by_gender(norm_women, 'Total Compensation for Women (<=$' + str(int(high_target / 1000)) + 'k )', 'crimson', high_target)\n"
      ],
      "metadata": {
        "id": "g56S4dgWbX-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_by_gender(norm_nb, 'Total Compensation for Nonbinary, Genderqueer, or Gender-Nonconforming Respondents (<=$' + str(int(high_target / 1000)) + 'k )', 'Purple', high_target)"
      ],
      "metadata": {
        "id": "UfvqsrMzbX1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_by_gender(norm_und, 'Total Compensation for those who Chose not to Disclose Gender (<=$' + str(int(high_target / 1000)) + 'k )', 'olive', high_target)"
      ],
      "metadata": {
        "id": "6QRnMDV8bZyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Upper Dataset"
      ],
      "metadata": {
        "id": "lP3v4YWcFE6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_by_gender(upper_men, 'SalarTotal Compensation for Men (>$' + str(int(high_target / 1000)) + 'k )', 'royalblue', maxSalary = 5_000_000, minSalary = 500_000, print_range = True)\n",
        "print(upper_men.shape[0])"
      ],
      "metadata": {
        "id": "1KN3a16RPkIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_by_gender(upper_women, 'Total Compensation for Women (>$' + str(int(high_target / 1000)) + 'k )', 'crimson', maxSalary = 5_000_000, minSalary = 500_000, print_range = True)\n",
        "print(upper_women.shape[0])"
      ],
      "metadata": {
        "id": "utZPBoQ5SzYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_by_gender(upper_nb, 'Total Compensation for Nonbinary, Genderqueer, or Gender-Nonconforming Respondents (>$' + str(int(high_target / 1000)) + 'k )', 'Purple', maxSalary = 5_000_000, minSalary = 500_000, print_range = True)"
      ],
      "metadata": {
        "id": "DF_Zz2-YS-77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_by_gender(upper_und, 'Total Compensation for those who Chose not to Disclose Gender (>$' + str(int(high_target / 1000)) + 'k )', 'olive', maxSalary = 5_000_000, minSalary = 500_000, print_range = True)"
      ],
      "metadata": {
        "id": "fw2eaQZxTF4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Gender Distribution"
      ],
      "metadata": {
        "id": "Kwj3K8obFi18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The survey respondents are overwhelmingly male. The gender distribution is essentially identically between the two earnings cohorts: when comparing the ratio of men to women between the two earnings cohorts, women are 5.12% of men among those making less than $550k, and 4.06% of men among those making more. "
      ],
      "metadata": {
        "id": "jTO36-rf0CA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_bar_graph(norm, 'Gender', 'Gender in the Norm dataset',  'Gender',  'Count')"
      ],
      "metadata": {
        "id": "poCgmqDluR1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_bar_graph(upper, 'Gender', 'Gender in the Upper Dataset',  'Gender',  'Count')"
      ],
      "metadata": {
        "id": "qq_FRpnNaZEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Age Distribution"
      ],
      "metadata": {
        "id": "XORp2ebmGAZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Almost half each dataset is between 25 and 34 years old, with  over 70% of each dataset being 25 and 44 years old. The upper dataset is ever so slightly older."
      ],
      "metadata": {
        "id": "CR4gGrxKcZ4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_bar_graph(norm, 'Age', 'Age among Lower - Earnings Respondents',  'Age Bracket',  'Count')"
      ],
      "metadata": {
        "id": "RCPc6YaYVuhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_bar_graph(upper, 'Age', 'Age among Upper - Earnings Respondents',  'Age Bracket',  'Count')"
      ],
      "metadata": {
        "id": "CMcx1_2gkP0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sexuality Distribution"
      ],
      "metadata": {
        "id": "69gARVVAGyDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each dataset has an essentially identical distribution by sexuality. 87% of both datasets identified as heterosexual."
      ],
      "metadata": {
        "id": "GPHzf54MG2L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_bar_graph(norm, 'Sexuality', 'Sexuality in Norm Dataset',  'Sexuality',  'Count')"
      ],
      "metadata": {
        "id": "iiyIi0g4mm8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_bar_graph(upper, 'Sexuality', 'Sexuality in Upper Dataset',  'Sexuality',  'Count')"
      ],
      "metadata": {
        "id": "iLEdYR_BqICC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_bar_graph(norm, 'Trans', 'Transgender Status among Respondents', 'Transgender Status', 'Count')"
      ],
      "metadata": {
        "id": "5ZmLy5m6qmfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transgender Distriubtion"
      ],
      "metadata": {
        "id": "ijaRfdP3JNlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "96-97% of respondents identified as not being transgender across both datasets."
      ],
      "metadata": {
        "id": "Zm_q_RsCJeDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_bar_graph(norm, 'Trans', 'Transgender Status in Norm Dataset', 'Transgender Status', 'Count')"
      ],
      "metadata": {
        "id": "EFN6oLdwJTRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_bar_graph(upper, 'Trans', 'Transgender Status in Upper Dataset', 'Transgender Status', 'Count')"
      ],
      "metadata": {
        "id": "hktZfbagoDly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ethnicity Distribution and Total Compensation by Ethnicity"
      ],
      "metadata": {
        "id": "SMk7zkUoJnn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There were lots of options the respondent could've picked between when it comes to ethnicity. And, like with gender, the respondent is able to pick as many options as they feel apply. With so many individual options to represent, making a graph for each one is a tall order. Instead, the dataset will be split into different dataframes of respondents whose ethnicity *includes* each individual option, and the mean and median total compensation for each will be displayed. Remember, the survey respondents come from across the world and have their respective currencies converted into USD, and features like gender aren't dilineated."
      ],
      "metadata": {
        "id": "ActXY1zzJx1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ethnicity_combos(dataframe):\n",
        "  uniques = dataframe['Ethnicity'].unique()\n",
        "  atoms = get_atoms(dataframe, 'Ethnicity')\n",
        "  print(f'There are a total of {len(uniques)} unique combinations chosen from {len(atoms)} individual options')"
      ],
      "metadata": {
        "id": "_uoOHxFDWGDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ethnicity_combos(norm)"
      ],
      "metadata": {
        "id": "cqI30EDMjEOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ethnicity_combos(upper)"
      ],
      "metadata": {
        "id": "SjTyQ-YUi3lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def salary_by_ethnicity(dataframe):\n",
        "  atoms = get_atoms(dataframe, 'Ethnicity')\n",
        "  noNaNs = dataframe.dropna(subset = ['Ethnicity'], inplace = False)\n",
        "  for atom in atoms:\n",
        "    if 'Indigenous' in atom: #Special case, is 0 otherwise somehow\n",
        "      atom = 'Indigenous'\n",
        "    ethnicity = noNaNs[noNaNs['Ethnicity'].str.contains(atom)]\n",
        "    number = ethnicity.shape[0]\n",
        "    percent = (round(100.0 * number / noNaNs.shape[0], 2))\n",
        "    print(f'{number} respondents include {atom} among their ethnicities, or {percent}%')\n",
        "    print(f'The average total compensation among this ethnicity is ${round(ethnicity[target].mean() / 1000, 2)}k, and the median is ${round(ethnicity[target].median() / 1000, 2)}k\\n')"
      ],
      "metadata": {
        "id": "n4vHR7blWy_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "salary_by_ethnicity(norm)"
      ],
      "metadata": {
        "id": "_y8CKuCAjTha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "salary_by_ethnicity(upper)"
      ],
      "metadata": {
        "id": "Qhd1TpuTjltm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DevType Distribution"
      ],
      "metadata": {
        "id": "f1bjL4VrJ5kZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Across both datasets, the most popular roles were front end, back end, and full stack. There aren't any significant differences in the distributions of developer type between the two datasets.\n",
        "\n",
        "Remember, since one person could pick multiple titles, the sum of these percentages won't be 100%! "
      ],
      "metadata": {
        "id": "aPzcRnllLFuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_bar_graph(norm, 'DevType', 'Distribution of Developer Titles', 'Title of Respondent', 'Count')"
      ],
      "metadata": {
        "id": "TqQivbqrJ16h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_bar_graph(upper, 'DevType', 'Distribution of Developer Titles', 'Title of Respondent', 'Count')"
      ],
      "metadata": {
        "id": "Pz1qw9S_PGqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Work Experience Distribtion"
      ],
      "metadata": {
        "id": "48zt_BBcMeZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most frequent number of years worked for each dataset is 3 years, at about 8% of respondents for both. However, for the next 3 most common responses to the question, the upper earners have been in the field a bit longer. The average for the 2nd-4th most frequent responses in the norm dataset is 2.67 years, while the average for the upper dataset is 7 years."
      ],
      "metadata": {
        "id": "rS3B5TOHMk5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workexp_bar_graph(norm, 'Work Experience for Lower Earnings Cohort')"
      ],
      "metadata": {
        "id": "Ei579kymzd0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workexp_bar_graph(upper, 'Work Experience for Higher Earnings Cohort')"
      ],
      "metadata": {
        "id": "wnyEZ0hkzgb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "AB9Y3TYuOxSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Encoding"
      ],
      "metadata": {
        "id": "EPs_hCHvPFFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As with most datasets, we arrive at the issue of encoding. Simple one-hot encoding results in such a monstrous amount of features, Google Colab runs out of RAM and interrupts execution. Even if we were to one-hot encode along the atoms of each choice and have them be indepententally applicable, instead of making a new feature for each unique combination of atoms selected, this could add dozens and dozens of new features per categorical feature. Going from about 20 features to hundreds of features is clearly not the greatest for dimensionality!\n",
        "\n",
        "Enter [target encoding](https://sci-hub.se/10.1145/507533.507538) (a less academic explanation is [here](https://maxhalford.github.io/blog/target-encoding/)\\). Essentially, each category within a feature is replaced by a blend of the mean target variable among all records that have that category in that feature  and the overall mean target.\n",
        "\n",
        "For example, if someone indicates their `Sexuality` as bisexual, this categorical string is replaced by a blend of the mean total compensation among all those who indicate their sexuality as solely `bisexual`  and the overall total compensation average. If their response was `bisexual;straight`, it would be encoded with a blend of the average total compensation of all those who chose `bisexual;straight` as their sexuality and the average overall total compensation.\n",
        "\n",
        "Target encoding has the benefit of creating no new features; not a single extra column is added to the data frame. And, as icing on the cake, target encoding can impute missing values as well. If someone skipped the question asking for their `Sexuality`, their `NaN` value would be replaced with a blend of the average total compensation of everyone else who skipped that question and the average overall total compensation."
      ],
      "metadata": {
        "id": "X76oVXdWyfvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_x_and_y(dataframe):\n",
        "  copy = dataframe.copy()\n",
        "  y = copy.pop(target)\n",
        "  return copy, y"
      ],
      "metadata": {
        "id": "RTm52m_Ko7a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Non-destructive function to return a target-encoded dataframe and its encoder\n",
        "def sample_target_encoding(dataframe):\n",
        "  encoder = TargetEncoder()\n",
        "  train_x, train_y = get_x_and_y(dataframe)\n",
        "  encoder.fit(train_x, train_y)\n",
        "  # Some encoders behave differently on whether y is given or not. This is mainly due to regularisation in order to avoid overfitting. \n",
        "  # On training data transform should be called with y, on test data without.\n",
        "  transformed = encoder.transform(train_x, train_y)\n",
        "  return transformed, encoder, train_y"
      ],
      "metadata": {
        "id": "7qL7rbngrhVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Non-destructive function to return a leave-one-out-encoded dataframe, its encoder, and the target variable\n",
        "def sample_loo_encoding(dataframe):\n",
        "  encoder = LeaveOneOutEncoder(sigma = 0.325)\n",
        "  train_x, train_y = get_x_and_y(dataframe)\n",
        "  encoder.fit(train_x, train_y)\n",
        "  # Some encoders behave differently on whether y is given or not. This is mainly due to regularisation in order to avoid overfitting. \n",
        "  # On training data transform should be called with y, on test data without.\n",
        "  transformed = encoder.transform(train_x, train_y)\n",
        "  return transformed, encoder, train_y"
      ],
      "metadata": {
        "id": "_iE-KJobP56R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Target Encoding Example"
      ],
      "metadata": {
        "id": "1Y0PDA72PUq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm.head(3)"
      ],
      "metadata": {
        "id": "JQfl2D_ijjPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_norm, norm_encoder, dummy = sample_target_encoding(norm)\n",
        "transformed_norm.head(3)"
      ],
      "metadata": {
        "id": "sJVJMFKjqy89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Leave-One-Out Encoding Example"
      ],
      "metadata": {
        "id": "6UwrFSLvPfTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leave One Out encoding is essentially target encoding except that the record currently being encoded is not used in the encoding calculation, and the sklearn implementation has support for introducing some Gaussian randomness into the result."
      ],
      "metadata": {
        "id": "nu-nuVPWa4V5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_norm, norm_encoder, norm_y = sample_loo_encoding(norm)\n",
        "transformed_norm.head(3)"
      ],
      "metadata": {
        "id": "otUegXluQlBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Correlations"
      ],
      "metadata": {
        "id": "GhpuitnpbF6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that everything in the dataframe has been encoded and imputed, we can look at correlations. `Ethnicity`, `YearsCodePro`, `Age`, and especially `Country` seem to be the highest predictors among the `norm` dataset, whereas the `upper` dataset doesn't seem to have any strong correlations except for `Country`, which has a weaker correlation of about 0.25 compared to the norm dataset's 0.45"
      ],
      "metadata": {
        "id": "WYG7Iktd1ljp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Norm Correlations"
      ],
      "metadata": {
        "id": "V0k9Sf5hb3V8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_norm[target] = norm_y\n",
        "transformed_norm.corr()"
      ],
      "metadata": {
        "id": "tcJlHciqQnAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Upper Correlations"
      ],
      "metadata": {
        "id": "UsrimFF9b8PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_upper, upper_encoder, upper_y = sample_loo_encoding(upper)\n",
        "transformed_upper[target] = upper_y\n",
        "transformed_upper.corr()"
      ],
      "metadata": {
        "id": "HeipdeAFsOeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Scaling and Principle Component Analysis"
      ],
      "metadata": {
        "id": "5oOPdtPecDDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before starting with the neural net, we'll create a function that, given a dataframe, will encode it, scale it, and perform PCA on it, returning data_x and data_y as tensors. This will fully preprocess the data and format it in a way that makes running it through the neural net easier."
      ],
      "metadata": {
        "id": "K-2KSKl9tbzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# As of now, we are not scaling the target variable.\n",
        "def scale_data(data_x, data_y):\n",
        "  scaler = StandardScaler()\n",
        "  scaler = scaler.fit(data_x)\n",
        "  result_x = scaler.transform(data_x)\n",
        "  result_y = data_y\n",
        "  # Don't scale Y\n",
        "  return result_x, result_y, scaler"
      ],
      "metadata": {
        "id": "0eP9GRNhq-2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensionality reduction\n",
        "def pca_data(data_x, verbose, variance):\n",
        "  pca = None\n",
        "  if variance == -1:\n",
        "    pca = PCA()\n",
        "  else:\n",
        "    pca = PCA(n_components = variance, svd_solver = 'full')\n",
        "  oldSize = len(data_x[0])\n",
        "  result = pca.fit_transform(data_x)\n",
        "  newSize = len(result[0])\n",
        "  if verbose:\n",
        "    print(f'Reduced data from {oldSize} features to {newSize} features')\n",
        "  return result"
      ],
      "metadata": {
        "id": "IvaAor9CrHN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the function we'll use. Given a dataset, an amount of variance to keep during PCA, and whether to print progress messages, the function will return the x data, the y data, and the scaler used "
      ],
      "metadata": {
        "id": "4d3l5AYWcazN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-destructive function that uses target encoding, a standard sklearn scaler, and PCA to preprocess a dataframe and return as a tensor_x and tensor_y\n",
        "def encode_normalize_pca(data, verbose = True, variance = -1): \n",
        "  warnings.filterwarnings(\"ignore\")\n",
        "  if verbose:\n",
        "    print('Beginning encoding')\n",
        "  data_x, encoder, data_y = sample_loo_encoding(data)\n",
        "  if verbose:\n",
        "    print(\"Encoding done\")\n",
        "  data_y = data_y.to_numpy()\n",
        "  if verbose:\n",
        "    print('Beginning normalization')\n",
        "  data_x, data_y, scaler = scale_data(data_x, data_y)\n",
        "  if verbose:\n",
        "    print('Normalization done')\n",
        "    print('Beginning PCA')\n",
        "  data_x = pca_data(data_x, verbose, variance)\n",
        "  if verbose:\n",
        "    print('PCA done\\n')\n",
        "  result_x = torch.tensor(data_x).float()\n",
        "  result_y = torch.tensor(data_y).float()\n",
        "  return result_x, result_y, scaler\n",
        "\n"
      ],
      "metadata": {
        "id": "LZuTOXhAkacE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Non-destructive way to convert a whole Pandas dataframe into a data_x and a data_y in tensor form\n",
        "def get_tensors(data):\n",
        "  copy = data.copy()\n",
        "  pandasY = copy.pop(target)\n",
        "  resultX = torch.tensor(copy.values)\n",
        "  resultY = torch.tensor(pandasY.values)\n",
        "  return resultX, resultY"
      ],
      "metadata": {
        "id": "iDoGyMxVKyHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def root_mean_squared_error(N, yPreds, yReals):\n",
        "  sum = torch.sum(torch.square(yPreds - yReals))\n",
        "  result = torch.sqrt(sum / N)\n",
        "  return result.item()"
      ],
      "metadata": {
        "id": "pbVi6jRH8yId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K is the number of features, actual are the real test_y values, and yHats are the predictions\n",
        "def r2_score(K, actual, yHats):\n",
        "  N = len(actual)\n",
        "  yActual = torch.Tensor(actual)  # actual as 1-d Tensor\n",
        "  yRealMean = torch.mean(yActual)\n",
        "  yHatMean = torch.mean(yHats)\n",
        "  numerator = (torch.sum(torch.square(yHats - yHatMean))).item()\n",
        "  denominator = (torch.sum(torch.square(yActual - yRealMean))).item()\n",
        "  if denominator == 0:\n",
        "    print(f'denominator is 0 for R2 score! Returning 1')\n",
        "    return 1\n",
        "  rSquared =  numerator / denominator\n",
        "  numerator = (1 - rSquared) * (N - 1)\n",
        "  denominator = N - K - 1\n",
        "  rSquaredAdjusted = 1 - (numerator/denominator)\n",
        "  return rSquaredAdjusted"
      ],
      "metadata": {
        "id": "h1BvQ6Yo9fsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deprecated for its inferior performance, but kept around for giggles\n",
        "def epoch_train(net, train_x, train_y, test_x, test_y, bat_size, epochs, begin, learning_rate, verbose):\n",
        "  num_prints = 5\n",
        "  net = net.train()  # Set training mode\n",
        "  loss_func = torch.nn.MSELoss()  # Mean squared error\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "  num_records = len(train_x)\n",
        "  batches = math.ceil(num_records / bat_size)\n",
        "  if verbose:\n",
        "    print(f'Running a total of {batches*epochs} batches and {epochs} epochs')\n",
        "  for epoch in range(epochs):\n",
        "    # Shuffle time!\n",
        "    shuffling = torch.randperm(len(train_x)) # Shuffling key\n",
        "    epoch_train_x = train_x[shuffling]\n",
        "    epoch_train_y = train_y[shuffling]\n",
        "    batches_x = torch.split(epoch_train_x, bat_size) # `N / bat_size` tensors of size `bat_size` x `features` each\n",
        "    batches_y = torch.split(epoch_train_y, bat_size)\n",
        "    for batch in range(len(batches_x)):\n",
        "      optimizer.zero_grad() # \"Sets the gradients of all optimized torch.Tensor s to zero.\" Resets for next grad descent?\n",
        "      oupt = net(batches_x[batch]) # Forward pass\n",
        "      loss_obj = loss_func(oupt, batches_y[batch])\n",
        "      loss_obj.backward()  # Compute gradients\n",
        "      optimizer.step()     # Update weights and biases, backward pass\n",
        "    if epoch % (epochs // num_prints) == 0: # prints num_prints times\n",
        "      currentTime = time.time()\n",
        "      elapsed = currentTime-begin\n",
        "      net = net.eval()\n",
        "      r2, rmse = r2_and_rmse(net, test_x, test_y)\n",
        "      net = net.train()\n",
        "      if verbose:\n",
        "        print(\"epoch = %6d\" % epoch, end=\"\\t\")\n",
        "        print(\"epoch loss = %7.0f   \" % loss_obj.item(), end=\"\\t\")\n",
        "        print(f\"R2 = {round(r2, 4)}\\tRMSE = ${round(rmse / 1000, 3)}k   \", end = \"\\t\")\n",
        "        print(f'\\tTime elapsed: {int(elapsed // 60)}m {int(elapsed % 60)}s ', end = '\\t')\n",
        "        print(f\"{100 * epoch // epochs}% done\")\n",
        "  currentTime = time.time()\n",
        "  elapsed = currentTime-begin\n",
        "  if verbose:\n",
        "    print(f\"\\nTraining complete. Time elapsed: {int(elapsed // 60)}m {int(elapsed % 60)}s\")\n",
        "  return net"
      ],
      "metadata": {
        "id": "S-i8gFvHTzjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_and_test(splits, test_index):\n",
        "  asList = list(splits)\n",
        "  test = asList.pop(test_index)\n",
        "  train = torch.cat(asList)\n",
        "  return train, test"
      ],
      "metadata": {
        "id": "K6yUTam7LR6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_datasets(set1, set2):\n",
        "  if len(set1) != len(set2):\n",
        "    return None, None\n",
        "  shuffling = torch.randperm(len(set1)) # Shuffling key\n",
        "  result1 = set1[shuffling]\n",
        "  result2 = set2[shuffling]\n",
        "  return result1, result2"
      ],
      "metadata": {
        "id": "p7057_DhT_73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Like lower function but also prints result\n",
        "def eval(net, test_x, test_y):\n",
        "  r2, rmse = r2_and_rmse(net, test_x, test_y)\n",
        "  print(f\"Model has R2 = {round(r2, 4)} and RMSE = ${round(rmse / 1000, 3)}k\\n\")\n",
        "  return r2, rmse\n",
        "\n",
        "def r2_and_rmse(net, test_x, test_y):\n",
        "  N = len(test_y)\n",
        "  net = net.eval()  # set eval mode\n",
        "  preds = net(torch.Tensor(test_x)).view(N) # all predicted as 1-d Tensor\n",
        "  # print(f'Making preds for eval, here\\'s what we\\'ve got\\n{preds}')\n",
        "  # preds = torch.exp(preds)  # Rescale predictions by exp for evaluation\n",
        "  R2 = r2_score(len(test_x[0]), test_y, preds)\n",
        "  rmse = root_mean_squared_error(N, preds, test_y)\n",
        "  absolute_diffs = preds - test_y\n",
        "  # print(f'\\nHow much each prediction overshoots the target: \\n{absolute_diffs}')\n",
        "  # print(f'Overall, the average overshoot is ${round(torch.mean(absolute_diffs).item() / 1000, 3)}k')\n",
        "\n",
        "  return R2, rmse"
      ],
      "metadata": {
        "id": "k2G2GkFrUDzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Regression Modeling"
      ],
      "metadata": {
        "id": "0ma0ProadAYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Neural Net Code"
      ],
      "metadata": {
        "id": "lT8KD42XdFDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The neural net! It has a configurable number of nodes per hidden layer and a configurable number of hidden layers, although always at least one. Each hidden layer will have the same number of nodes, and the model will output a single continuous value. Nodes have their weights initialized according to Xavier intialization and their biases initialized to 0."
      ],
      "metadata": {
        "id": "0TDKYg4-U6tW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Will always have at least one hidden layer\n",
        "class NeuralNet(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, num_inputs, hidden_layers, hidden_layer_nodes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.hiddenLayers = torch.nn.ModuleList()\n",
        "    firstHidden = torch.nn.Linear(num_inputs, hidden_layer_nodes)\n",
        "    self.hiddenLayers.append(firstHidden) #maps input to the first hidden layer\n",
        "    torch.nn.init.xavier_uniform_(self.hiddenLayers[0].weight) # Randomizes weights for this mapping via the Xavier/Glodot intitialization technique\n",
        "    torch.nn.init.zeros_(self.hiddenLayers[0].bias) # Sets the biases to 0 for this mapping\n",
        "\n",
        "    for layer in range(1, hidden_layers):  # start at 1 since the initial input layer maps to a hidden layer\n",
        "      self.hiddenLayers.append(torch.nn.Linear(hidden_layer_nodes, hidden_layer_nodes))\n",
        "      torch.nn.init.xavier_uniform_(self.hiddenLayers[layer].weight)\n",
        "      torch.nn.init.zeros_(self.hiddenLayers[layer].bias)\n",
        "    \n",
        "    self.hiddenLayers.append(torch.nn.Linear(hidden_layer_nodes, 1)) # Output layer\n",
        "    torch.nn.init.xavier_uniform_(self.hiddenLayers[-1].weight)\n",
        "    torch.nn.init.zeros_(self.hiddenLayers[-1].bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # print(f'{x} is being fed forward')\n",
        "    activation_func = torch.nn.LeakyReLU()\n",
        "    z = activation_func(self.hiddenLayers[0](x))\n",
        "    # print(f'fed forward,\\n{x}\\n is now {z}\\n')\n",
        "    for layer in range(1, len(self.hiddenLayers) - 1): # Start from 1 since (input->1st_hidden) is done outside of the loop\n",
        "      z = activation_func(self.hiddenLayers[layer](z))\n",
        "      # print(f'fed forward, z is now {z}\\n')\n",
        "    # Last layer will be done outside the loop as an identity/ReLU\n",
        "    lastFunc = torch.nn.Identity()\n",
        "    z = lastFunc(self.hiddenLayers[-1](z))\n",
        "    # print(f'last feed forward, output is {z}\\n\\n')\n",
        "    return z"
      ],
      "metadata": {
        "id": "kH5tCSpDJW-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I found myself in the curious circumstance that the net would sometimes not train at all over a cross-validation fold. As in, a drop from maybe 69_000 root mean squared error to around 67_000 after maybe 5min in that fold. Any time I have it train for longer, it'll always pretty much stay at whatever RMSE it started at. Some hyperparameter tuning helped or hurt the initial value, but nothing I tweaked resulted in actual learning. \n",
        "\n",
        "Hoping to see where the issue is, I slimmed down the test and train set to a single record among the both of them, and something even weirder happens. Sometimes the model will converge and get down to within 1 RMSE in a matter of 100 or 200 epochs. Sometimes, however, the net will only ever spit out a prediction of 0 every time and literally train none at all even on a train and test set made of the same singular record. The RMSE at the end of the full cross validation is literally the exact same as the test_y value. \n",
        "\n",
        "I'm most confused since I can run the exact same code back to back, taking a random record each time, and sometimes the model will converge and sometimes it just spits out 0s. Right now the net is just 22 input nodes, a single hidden layer of 14 nodes, and a singular output node. Data_x is encoded and scaled from [0,1] while data_y isn't. Activation functions I've tried include ReLU, ELU, sigmoid, and Tanh. All of them have this problem, but when Sigmoid and Tanh learn it's at a glacial rate (RMSE from 76_000 to 75_469 after 200 epochs and one record). Using Xavier initialization for weights. Before implementing proper cross validation, the net would improve its training accuracy but I'm not sure if the test accuracy has ever improved."
      ],
      "metadata": {
        "id": "TH6o64_up60I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cross Validate Model"
      ],
      "metadata": {
        "id": "XvKoNYsndgs7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is the main heavy lifter of the entire notebook. Given some hyperparameters and a dataframe, it will return the Root mean Squared Error and the R<sup>2</sup> score across each fold and over the entire cross validation. The process goes like this:\n",
        "\n",
        "*    If `shuffling` is set to true, the dataframe has the order of its records randomly shuffled\n",
        "*    The data is split into K folds\n",
        "*    The neural net object is initialized according to the given hyperparameters\n",
        "*    The neural net is trained, giving printouts for the model's performance according to the given fold's test set 5 times each fold\n",
        "     *    If `train_by_epoch` is set to true, the neural net is trained by shuffling the training and test data, feeding in `batch_size` records, and running backpropagation until all records in the dataset have been fed through. This process is repeated `epoch` times\n",
        "     *    If `train_by_epoch` is set to false, the neural net is trained by feeding in `batch_size` random records then running back propogation a total of `epochs * num_records // batch_size` times\n",
        "*    At the end of training, the Root Mean Squared Error and R<sup>2</sup> scores are printed and returned"
      ],
      "metadata": {
        "id": "DX_3vN5_di3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validate_model(data, hidden_layers, shuffle = True, train_by_epoch = False, nodes_per_layer = None, bat_size = 10, variance = 0.95, epochs = 1000, partitions = 5, learning_rate = 0.01, verbose = True):\n",
        "  begin = time.time()\n",
        "  copy = data.copy()\n",
        "  features = len(data_x[0])\n",
        "  hidden_nodes = nodes_per_layer\n",
        "  if hidden_nodes == None:\n",
        "    hidden_nodes = (features * 2) // 3 # if nodes per hidden layer unspecified, set to 2/3 the number of features\n",
        "  # shuffle\n",
        "  if shuffle:\n",
        "    if verbose:\n",
        "      print('Shuffling before cross validation!')\n",
        "    copy.sample(frac = 1).reset_index(drop = True)\n",
        "  else:\n",
        "    if verbose:\n",
        "      print('No shuffling before cross validation')\n",
        "  # Split into k folds\n",
        "  partitions_x = torch.tensor_split(data_x, partitions)\n",
        "  partitions_y = torch.tensor_split(data_y, partitions)\n",
        "  r_squared = 0\n",
        "  rmse = 0\n",
        "  for partition in range(partitions):\n",
        "    if verbose:\n",
        "      print(f'Beginning fold {partition + 1} of {partitions}')\n",
        "    train_x, test_x = get_train_and_test(partitions_x, partition)\n",
        "    train_y, test_y = get_train_and_test(partitions_y, partition)\n",
        "    # if verbose:\n",
        "    #   train_x = data_x[10:12]\n",
        "    #   train_y = torch.tensor(data_y[10:12])\n",
        "    #   test_x = train_x\n",
        "    #   test_y = train_y\n",
        "    #   print(f'train_x {train_x}')\n",
        "    #   print(type(train_x))\n",
        "    #   print(f'train_y {train_y}')\n",
        "    #   print(type(train_y))\n",
        "    # need to preprocess here\n",
        "    net = NeuralNet(features, hidden_layers, hidden_nodes)\n",
        "    if train_by_epoch:\n",
        "      epoch_train(net, train_x, train_y, test_x, test_y, bat_size, epochs, begin, learning_rate, verbose)\n",
        "    else:\n",
        "      if verbose:\n",
        "        print('Training with random sampling')\n",
        "      net = random_sampling_train(net, train_x, train_y, test_x, test_y, bat_size, epochs, begin, learning_rate, verbose)\n",
        "    r_squareAdd, rmseAdd = eval(net, test_x, test_y)\n",
        "    r_squared = r_squared + (r_squareAdd / partitions)\n",
        "    rmse = rmse + (rmseAdd / partitions)\n",
        "  currentTime = time.time()\n",
        "  elapsed = currentTime-begin\n",
        "  if verbose:\n",
        "    print(f'Validation complete! ({int(elapsed // 60)}m {int(elapsed % 60)}s elapsed)')\n",
        "    print(f\"Cross-validated model with {partitions} partitions has:\\nR2 = {round(r_squared, 4)}\\t RMSE = ${round(rmse / 1000, 2)}k\")\n",
        "    print(f'hidden_layers = {hidden_layers}, bat_size = {bat_size}, nodes_per_layer = {hidden_nodes}, variance = {variance}, epochs = {epochs}, learning_rate = {learning_rate}')\n",
        "  return r_squared, rmse"
      ],
      "metadata": {
        "id": "XBgrcg5vhOMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_sampling_train(net, train_x, train_y, test_x, test_y, bat_size, epochs, begin, learning_rate, verbose):\n",
        "  # print(f'Here\\'s the test set for this fold:\\n{test_y}')\n",
        "  num_prints = 5\n",
        "  net = net.train()  # Set training mode\n",
        "  loss_func = torch.nn.MSELoss()  # Mean squared error\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "  n_items = len(train_x)\n",
        "  batches_per_epoch = n_items // bat_size\n",
        "  max_batches = epochs * batches_per_epoch\n",
        "  if verbose:\n",
        "    print(f'Running a total of {max_batches} batches')\n",
        "  for b in range(max_batches):\n",
        "    curr_bat = np.random.choice(n_items, bat_size,\n",
        "      replace=False)\n",
        "    X = torch.Tensor(train_x[curr_bat])\n",
        "    Y = torch.Tensor(train_y[curr_bat]).view(bat_size,1)\n",
        "    # X = torch.Tensor(train_x)\n",
        "    # Y = Tensor(train_y)\n",
        "    # Y = torch.log(Y)  # Scale y values down to their log for training\n",
        "    optimizer.zero_grad()\n",
        "    oupt = net(X)\n",
        "    loss_obj = loss_func(oupt, Y)\n",
        "    loss_obj.backward()\n",
        "    optimizer.step()\n",
        "    if b % (max_batches // num_prints) == 0: # prints num_prints times\n",
        "      currentTime = time.time()\n",
        "      elapsed = currentTime-begin\n",
        "      net = net.eval()\n",
        "      r2, rmse = r2_and_rmse(net, test_x, test_y)\n",
        "      net = net.train()\n",
        "      if verbose:\n",
        "        print(\"batch = %6d\" % b, end=\"\\t\")\n",
        "        print(\"batch loss = %3.4f   \" % loss_obj.item(), end=\"\\t\")\n",
        "        print(f\"R2 = {round(r2, 4)}\\tRMSE = ${round(rmse / 1000, 3)}k   \", end = \"\\t\")\n",
        "        print(f'\\tTime elapsed: {int(elapsed // 60)}m {int(elapsed % 60)}s ', end = '\\t')\n",
        "        print(f\"{100 * b // max_batches}% done\")\n",
        "  currentTime = time.time()\n",
        "  elapsed = currentTime-begin\n",
        "  if verbose:\n",
        "    print(f\"\\nTraining complete. Time elapsed: {int(elapsed // 60)}m {int(elapsed % 60)}s\")\n",
        "  return net"
      ],
      "metadata": {
        "id": "0MD7mc0VeysN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_hispanic  = norm.dropna(subset = ['Ethnicity'])\n",
        "norm_hispanic =  norm_hispanic[norm_hispanic['Ethnicity'].str.contains('Hispanic')]\n",
        "norm_america =  norm[norm['Country'] == 'United States of America'].copy()\n",
        "america_jobs = norm_america.dropna(subset = ['DevType'], inplace = False)\n",
        "print(america_jobs.shape)\n",
        "america_ds = america_jobs[america_jobs['DevType'].str.contains('Data scientist')].copy()\n",
        "america_ds = america_ds[america_ds[target] > 60_000].copy()\n",
        "america_ds.shape"
      ],
      "metadata": {
        "id": "-pU3OKsjnnVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_layers = 3\n",
        "nodes_per_layer = None\n",
        "bat_size = 20\n",
        "epochs = 1_000\n",
        "variance = 0.95\n",
        "partitions = 5\n",
        "learning_rate = 0.01\n",
        "\n",
        "rsquare, rmse = cross_validate_model(america_ds, hidden_layers = hidden_layers, nodes_per_layer = nodes_per_layer, bat_size = bat_size, epochs = epochs, variance = variance, partitions = partitions)"
      ],
      "metadata": {
        "id": "TYCuFKHiH4Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two features were tested: shuffling the training and test data before partitioning, and randomly sampling `number_records / batch_size` batches from the data  vs sequentially taking `batch_size` records from the training set. The results are as  follows, sorted by the best Root Mean Squared Error\n",
        "\n",
        "*    Shuffling, random sample training Model has R2 = 0.547 and RMSE = \\$53.833k\n",
        "*    No shuffling, random sample training R2 = 0.4835\t RMSE = \\$57.1k\n",
        "*    No shuffling, sequential epoch training Model has R2 = -0.0023 and RMSE = \\$73.832k\n",
        "*      Shuffling before, sequential epoch training Model has R2 = -0.0052 and RMSE = \\$74.111k\n",
        "\n",
        "\n",
        "The best results were with random sampling and a shuffled dataset. Randomly sampling the data makes the biggest difference, and shuffling before partitioning into a training and test dataset also helps a bit on top of that. Shuffling doesn't make much of a difference  when training sequentially through the epoch.\n",
        "\n",
        "Thus, from now on, we will be shuffling before partitioning and randomly sampling records from the data."
      ],
      "metadata": {
        "id": "BPVyprUH_L6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next steps:\n",
        "*    Shuffle data pre-partitioning to see if cross validation loses the appearance of \"building up\" on the last cross. If that doesn't work, try printing weights upon start and end of each fold\n",
        "*    Look into validity of R<sup>2</sup> as an evaluation metric for this use case https://statisticsbyjim.com/regression/r-squared-invalid-nonlinear-regression/\n",
        "*    Look into using other activation functions\n",
        "*    Look into further dividing the dataset \n",
        "*    Research neural nets for use in regression in particular\n",
        "*    Look into feature engineering and hyperparameter tuning"
      ],
      "metadata": {
        "id": "7yXpupYX7LFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using ReLU with learning rate of 0.01, Adams optimizer, batch size of 20, 100 epochs, keeping 95% of the variance during PCA, with 5 Fold cross validation yields a RMSE of about \\$56k\n",
        "* Switching the dataset to not be restricted to America? Boom, 54.59k RMSE\n",
        "*    LeakyReLU makes very little difference, possibly even slightly worse\n",
        "*    RReLU about the same, 56.9k\n",
        "*    GELU about the same, 57k\n",
        "*    ELU a bit worse, 58.45k\n",
        "*    PReLU maybe a bit better, 56.43k\n",
        "*    Adjusting learning rate from 0.01 makes it worse at 0.1, goes from 56k to 58k RMSE, lowering to 0.005 or 0.001 keeps around 56k RMSE"
      ],
      "metadata": {
        "id": "HWL2EwOucFw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_x, data_y, encoder = encode_normalize_pca(norm_america)"
      ],
      "metadata": {
        "id": "fewq6YuF_L_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pare_features(dataframe, features):\n",
        "  result = pd.DataFrame([])\n",
        "  for feature in features:\n",
        "    result[feature] = dataframe[feature]\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "rLI4AaZ2I-y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_features(data, hidden_layers, shuffle = True, train_by_epoch = False, nodes_per_layer = None, bat_size = 10, variance = 0.95, epochs = 1000, partitions = 5, learning_rate = 0.01, verbose = True):\n",
        "  dataframe = data.copy()\n",
        "  targets = dataframe.pop(target)\n",
        "  num_features = dataframe.shape[1]\n",
        "  columns = dataframe.columns\n",
        "  bestRMSE = 200_000\n",
        "  toUse = []\n",
        "  for to_include in range(2, num_features):\n",
        "    print(f'Checking for {to_include} features.\\nBest RMSE so far: {bestRMSE}')\n",
        "    print(f'Best features: {toUse}\\n')\n",
        "    subsets = list(itertools.combinations(columns, to_include))\n",
        "    for subset in subsets:\n",
        "      newData = pare_features(dataframe, subset)\n",
        "      newData[target] = targets\n",
        "      r_squared, rmse = cross_validate_model(data = newData, hidden_layers = hidden_layers, shuffle = shuffle, train_by_epoch = train_by_epoch, nodes_per_layer = nodes_per_layer, bat_size = bat_size, epochs = epochs, variance = variance, partitions = partitions, verbose = verbose)\n",
        "      if rmse < bestRMSE:\n",
        "        bestRMSE = rmse\n",
        "        toUse = subset\n",
        "      "
      ],
      "metadata": {
        "id": "OctJjQjKTyPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_layers = 3\n",
        "nodes_per_layer = None\n",
        "bat_size = 20\n",
        "epochs = 1_000\n",
        "variance = -1\n",
        "partitions = 5\n",
        "learning_rate = 0.01\n",
        "\n",
        "usable = survey.dropna(subset = [target])\n",
        "usable = usable[usable[target] <= high_target]\n",
        "find_best_features(usable, hidden_layers = hidden_layers, verbose = True)"
      ],
      "metadata": {
        "cellView": "code",
        "id": "_sh3IuNDLnEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subsets = list(itertools.combinations(norm.columns, 2))\n",
        "subset = subsets[0]\n",
        "newData = pd.DataFrame([])\n",
        "for feature in subset:\n",
        "  newData[feature] = norm[feature]\n",
        "newData.head()"
      ],
      "metadata": {
        "id": "O1jWBYWlFspS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1XsAeeAhGFkc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}